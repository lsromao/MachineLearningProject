{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Visual Concept Detection Task</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group:\n",
    " - Nooshin Shojaee\n",
    " - Francesco Ciraolo\n",
    "     - Student#: 020167902F\n",
    " - Lucas Souza Romao\n",
    "     - Student#: 0190727830"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of the evaluation of the semester a challenge was given based on ImageCLEF 2008: Visual Concept Detection Task [[1]](#1).\n",
    "This challenge utilizes the IAPR TC-12 dataset that contains a split in the train set with x images and a test set with x images. Each of these images can have more than one classification associated with it. As it is a multi-classification problem the decision was to utilize a convolutional neural network (CNN), for better accuracy we decide to move forward in the utilization of EfficientNet as the main model, it provides us better results than ResNet50.\n",
    "In the next sections, we will be giving a walkthrough of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enviroments Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the frameworks we will be mainly utilizing Keras that runs on top the Tensorflow [[2]](#2) plataform, also to support the plot of the images matplot and seaborn are being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "from PIL import Image\n",
    "import imghdr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score,roc_curve, confusion_matrix, auc\n",
    "from scipy import interp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pics_dir = './train/train/'\n",
    "test_pics_dir = './test/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test/test.anno.txt', sep=\" \")\n",
    "labels = test_df.columns\n",
    "file_names = test_df['file_name']\n",
    "#test_df['file_name'] = test_df['file_name'].apply(lambda x: os.path.join(test_pics_dir, x))\n",
    "test_df['classes'] = test_df.loc[:, (test_df.columns != 'file_name')].values.tolist()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train/train.anno.txt', sep=\" \", names=labels)\n",
    "#train_df['file_name'] = train_df['file_name'].apply(lambda x: os.path.join(train_pics_dir, x))\n",
    "#train_df['classes'] = add_labels_dataframe(train_df)\n",
    "train_df['classes'] = train_df.loc[:, (train_df.columns != 'file_name')].values.tolist()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_freq = []\n",
    "\n",
    "for column in train_df:\n",
    "    if train_df[column].name != 'file_name' and train_df[column].name != 'classes':\n",
    "        labels_freq.append(\n",
    "            [train_df[column].name, \n",
    "            train_df[column].value_counts()[1]\n",
    "            ])\n",
    "    df_labels_freq = pd.DataFrame(labels_freq, columns = ['Label', 'Count']).sort_values(by=['Count'], ascending=False)\n",
    "\n",
    "style.use(\"fivethirtyeight\")\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.barplot(y=df_labels_freq.Label, x=df_labels_freq.Count)\n",
    "plt.title(\"Label frequency - Training Set\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be noticed in the plot above, our train set is imbalance, it will be a problem for our model because the difference between the majority classes such as outdoor, day and sky and the minority classes such as night, beach and animal, to overcome this problem we tried to use techniques to oversampling the minority ones and under sampling the majority. For it utilized SMOTETomek that is a combination of over and under sampling using SMOTE and Tomek links.[[3]](#3)\n",
    "However the results after gave us a train set with more than 8 thousand obersavations as it can been seeing below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"over.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the classes are more well balanced but still not in the ideal, to have a better view about this effect of a big enlarge in our training set we can see the correlation plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_df.corr(), linewidths=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the labels are quite well correlated so the under and oversampling doesn't help in our problem as always we can be increasing a majority class by doing oversampling of a minory one, to overcome it the class weights will be calculate in order to give those wieghts as parameters in the model, it will kind say to our model during the training to pay more attention in the labeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the data will be handle in order to utilize it to train the model, for it we decide to utilize ImageDataGenerator provided by Tensorflow, generator are a easy way to handle data since it is possible to add data argumentation on it and generate the images for the model.\n",
    "For the input size of the image since EfficientNetB2 was choose, it requires an image size of 260x260. The channel will be the same RGB. \n",
    "For the batch size the best results were with the size of 32. But also tried with 16, 64 and 120."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels_dataframe(dataset):\n",
    "    \n",
    "    df = dataset.copy()\n",
    "    \n",
    "    for column in df.loc[:, df.columns != 'file_name']:\n",
    "        df[column]= df[column].replace(1,df[column].name)\n",
    "    \n",
    "    df['classes'] = df.loc[:, (df.columns != 'file_name')].values.tolist()\n",
    "    df['classes']= df['classes'].apply(lambda x : list(filter(lambda b: b != 0, x)))\n",
    "    \n",
    "    return df['classes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS = 3\n",
    "IMG_HEIGHT = 260\n",
    "IMG_WIDTH = 260\n",
    "BATCH_SIZE = 2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {}\n",
    "weights =list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "train_size = len(train_df)\n",
    "\n",
    "for column in train_df:\n",
    "    if train_df[column].name != 'file_name' and train_df[column].name != 'classes':\n",
    "        class_weights[index] = len(train_df[train_df[column] == 1]) / train_size\n",
    "        weights.append(len(train_df[train_df[column] == 1]) / train_size)\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to create the Data Generator for each set, note that the only set that will be argumentated is the train set, we don't want the validation and test set with image transformations besides a rescale, otherwise the accurancy and predictions can be misleading.\n",
    "As the total number of images are not so expressive due this the validation set will be 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ImageDataGenerator(rescale=1./255,\n",
    "                               rotation_range=45,\n",
    "                               shear_range=0.2,\n",
    "                               zoom_range=0.4,\n",
    "                               horizontal_flip=True,\n",
    "                               vertical_flip=True)\n",
    "\n",
    "val_test = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = train.flow_from_dataframe(dataframe=train_df,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               directory=train_pics_dir,\n",
    "                                               x_col='file_name',\n",
    "                                               y_col=train_df.columns[1:18].tolist(),\n",
    "                                               shuffle=True, seed=42,\n",
    "                                           class_mode='raw',\n",
    "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "\n",
    "val_data_gen = val_test.flow_from_dataframe(dataframe=val_df,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             directory=train_pics_dir,\n",
    "                                             x_col='file_name',\n",
    "                                             y_col=train_df.columns[1:18].tolist(),\n",
    "                                             shuffle=False, seed=42,\n",
    "                                             class_mode='raw',\n",
    "                                       target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "\n",
    "test_generator = val_test.flow_from_dataframe(dataframe=test_df,\n",
    "                                                directory=test_pics_dir,\n",
    "                                                x_col='file_name',\n",
    "                                                y_col=None,\n",
    "                                                batch_size=1,\n",
    "                                                shuffle=False,\n",
    "                                                class_mode=None,\n",
    "                                                target_size=(IMG_HEIGHT, IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model EfficientNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behind EfficinetNet there is an intuition published by Mingxing Tan and Quoc V. Le, published with a paper in May 2019. The idea is, for the convolutional neural networks, to overcome the monodimensional scaling, a widely shared approach. In the monodimensional scaling is required to chose between network width, network depth and image resolution. In EfficientNet all the three previous mentioned dimensions are scaled at the same time.\n",
    "\n",
    "\n",
    "![scaling_comparison](img/scaling_comparison.png)\n",
    "\n",
    "\n",
    "The compound scaling allows, how the paper shows, to obtain better results with fewer parameters.\n",
    "\n",
    "\n",
    "![results_comparison](img/results_comparison.png)\n",
    "\n",
    "\n",
    "We had two main reasons to implement this method. The first motive is contextualized to the challenge approach of this project; we decided to be more \"adventurous\" and try to implement a newer and promising model over a older but more stable one. The second reason is that, having this opportunity, would be a gr\n",
    "\n",
    "Our main raisons to implement this method are:\n",
    "- A great interest in this promising approach\n",
    "- The attempt to solve the challenge limiting the re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behind EfficinetNet there is an intuition published by Mingxing Tan and Quoc V. Le, published with a paper in May 2019. The idea is, for the convolutional neural networks, to overcome the monodimensional scaling, a widely shared approach. In the monodimensional scaling is required to chose between network width, network depth and image resolution. In EfficientNet all the three previous mentioned dimensions are scaled at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effic_b2 = EfficientNetB2(weights=None, \n",
    "                          include_top=False, \n",
    "                          drop_connect_rate=0.2, \n",
    "                          pooling='avg', \n",
    "                          input_shape=(IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(effic_b2)\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(17, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explain our model, as the output layer we have the sigmoid as activation function since the problem has non-exclusive labels for each image, otherwise Softmax would be use [[4]](#4). As the optmizer Adam was choose and for the loss since we are using Sigmoid it  is binary cross entropy. Worth it to mentioned that a run was made using Softmax and categorical cross entropy but the loss was increasing very fast and results were not accurate at all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                        factor=0.2, \n",
    "                        patience=3, \n",
    "                        verbose=1,\n",
    "                        mode='auto', \n",
    "                        min_delta=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate is not being set, the default when using Adam without specifing this rate is <i>learning_rate=0.001</i> as can be found in the documentation. Why? Because we want to make sure that our model don't stop learn, so after 3 epochs that is not improving it will get the factor and calculate a new learning rate utilizing: <i>new_lr = lr * factor</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we suggest to use HPC facilities [[5]](#5) for a faster tranining, together with this notebook we will be adding the python file only with the necessary code to read the sets and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model_trained = model.fit(\n",
    "        train_data_gen,\n",
    "        steps_per_epoch=train_data_gen.n//train_data_gen.batch_size,\n",
    "        epochs = 2,\n",
    "        callbacks=[reduce_lr],\n",
    "        validation_data=val_data_gen,\n",
    "        validation_steps=val_data_gen.n//val_data_gen.batch_size,\n",
    "        class_weight=class_weights\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained.model.save('model_b2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TTraining and validation loss\n",
    "loss = model_trained.history['loss']\n",
    "val_loss = model_trained.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('loss_b2.jpg')\n",
    "plt.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and validation accuracy\n",
    "plt.plot(epochs, model_trained.history[\"accuracy\"], 'y', label='Training Accuracy')\n",
    "plt.plot(epochs, model_trained.history[\"val_accuracy\"], 'r', label='Validation Accuracy')\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('accurancy_b2.jpg')\n",
    "plt.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, model_trained.history[\"lr\"])\n",
    "plt.title(\"Learning Rate\")\n",
    "plt.ylabel(\"LR\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.savefig('learning_curve.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model in case of it being trainned in HPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained = tf.keras.models.load_model('model_b2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "yhat = model_trained.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = (yhat > 0.5).astype(\"int32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classes = np.array(list(test_df.classes.values))\n",
    "thresholds = np.arange(0, 1, 0.001)\n",
    "\n",
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')\n",
    "\n",
    "scores = [f1_score(test_classes, to_labels(yhat, t), average='micro') for t in thresholds]\n",
    "\n",
    "ix = tf.argmax(scores)\n",
    "print('Threshold=%.3f, F-Score=%.5f' % (thresholds[ix], scores[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tt = pd.DataFrame(data=yhat, columns=labels[1:].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_dict = {}\n",
    "\n",
    "for i in labels[1:]:\n",
    "    precision, recall, thresholds = precision_recall_curve(test_df[i].values, df_tt[i].values)\n",
    "    fscore = (2 * precision * recall) / ( precision + recall)\n",
    "    ix = tf.argmax(fscore)\n",
    "    thresholds_dict[i] = thresholds[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For to have a better F1 result, first we need to find the optimal threshold, so each label will have their own threshold, in order to achieve it the harmonic mean of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in thresholds_dict:\n",
    "    df_tt[i] = df_tt[i].map(lambda x: 1 if x > thresholds_dict[i] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tt['file_name'] = test_df['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tt.to_csv('./test/test.eval_b21.txt', index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('./test/eval.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'>[1]</a>   ImageCLEF. <i>ImageCLEF 2008: Visual Concept Detection Task.</i> URL:https://www.imageclef.org/2008/vcdt.\n",
    "\n",
    "<a id='2'>[2]</a>   Tensorflow. <i>Tensorflow.</i> URL:https://www.tensorflow.org/about\n",
    "\n",
    "<a id='3'>[3]</a>   SMOTETomek. <i>imbalanced-learn.</i> URL:https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.combine.SMOTETomek.html\n",
    "\n",
    "<a id='4'>[4]</a>   Jason Brownlee. <i>Multi-Label Classification with Deep Learning</i> URL:https://machinelearningmastery.com/multi-label-classification-with-deep-learning/\n",
    "\n",
    "<a id='4'>[5]</a>  S.  Varrette  et  al. “Management  of  an  Academic  HPCCluster:  The  UL  Experience”.  In:<i>Proc. of the 2014Intl. Conf. on High Performance Computing & Sim-ulation (HPCS 2014)</i> . Bologna, Italy: IEEE, July 2014,pp. 959–967."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
